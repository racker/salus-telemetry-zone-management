substitutions:
  _GCS_CACHE_BUCKET: salus-cache
  _SALUS_PROJECT: salus-telemetry-zone-watcher
  _SALUS_APP: zone-watcher
  _APP_NAMESPACE: default
  _CLOUDSDK_COMPUTE_ZONE: us-east1-b
  _CLOUDSDK_CONTAINER_CLUSTER: salus-dev

steps:

    # This is ugly because of
    # https://github.com/GoogleContainerTools/jib/issues/1500#issuecomment-466207421
  - id: FIX_DOCKER
    name: gcr.io/cloud-builders/mvn
    waitFor: ['-']
    dir: /root
    entrypoint: bash
    args:
    - -c
    - # Links the Docker config to /root/.docker/config.json so that Jib picks it up.
      # Note that this is only a temporary workaround.
      # See https://github.com/GoogleContainerTools/jib/pull/1479.
      |
      mkdir .docker &&
      ln -vs $$HOME/.docker/config.json .docker/config.json
    volumes:
    - name: user.home
      path: /root

  # Pull down settings file for Artifactory settings
  - id: GET_SETTINGS
    name: 'gcr.io/cloud-builders/gsutil'
    waitFor: ['-']
    args: ['cp', 'gs://salus-mavenrepository/m2-settings.xml', '.mvn/settings.xml']

  # Load the cached files from GCS if they exist.
  - id: PULL_DOWN_CACHE
    waitFor: ['-']
    name: gcr.io/cloud-builders/gsutil
    dir: /root
    entrypoint: bash
    args:
    - -c
    - |
      (
        gsutil cp gs://${_GCS_CACHE_BUCKET}/${_SALUS_PROJECT}-m2-cache.tar.gz /tmp/m2-cache.tar.gz &&
        tar -xzf /tmp/m2-cache.tar.gz
      ) || echo 'Cache not found'
    volumes:
    - name: user.home
      path: /root

  - id: DEPLOY
    name: 'gcr.io/cloud-builders/mvn'
    args: ['-B', 'deploy', '-s', '.mvn/settings.xml']
    volumes:
    - name: user.home
      path: /root

  - id: COMPILE_AND_PUSH_CONTAINER
    name: 'gcr.io/cloud-builders/mvn'
    env:
    - 'SHORT_SHA=$SHORT_SHA'
    args:
    - compile
    # Runs the Jib build by using the latest version of the plugin.
    # To use a specific version, configure the plugin in the pom.xml.
    - jib:build
    - "-B"
    # Skip Tests since it happened in the previous test
    - "-Dmaven.test.skip=true"
    # Ensure we name the image correctly since its not in pom.xml
    - "-Ddocker.image.prefix=gcr.io/$PROJECT_ID"
    - "-s"
    - .mvn/settings.xml
    volumes:
    - name: user.home
      path: /root

  # Saves the files to the GCS cache.
  - id: PUSH_UP_CACHE
    waitFor:
    - COMPILE_AND_PUSH_CONTAINER
    name: gcr.io/cloud-builders/gsutil
    dir: /root
    entrypoint: bash
    # Caches the local Maven repository.
    args:
    - -c
    - |
      set -ex
      tar -czf /tmp/m2-cache.tar.gz .m2 &&
      gsutil cp /tmp/m2-cache.tar.gz gs://${_GCS_CACHE_BUCKET}/${_SALUS_PROJECT}-m2-cache.tar.gz
    volumes:
    - name: user.home
      path: /root

  - name: gcr.io/cloud-builders/git
    id: HELM_CLONE
    waitFor:
    - COMPILE_AND_PUSH_CONTAINER
    - PUSH_UP_CACHE
    args: ['clone', 'https://source.developers.google.com/p/$PROJECT_ID/r/github_rackspace-segment-support_helm-salus-${_SALUS_APP}', '/workspace/helm-salus-${_SALUS_APP}/']

  # Set _CLOUDSDK_COMPUTE_REGION in the build trigger for non-dev clusters
  - name: 'gcr.io/$PROJECT_ID/helm'
    id: DEPLOY_APPLICATION
    args: ['upgrade', '--install', '--wait', '${_SALUS_APP}', '--namespace', '${_APP_NAMESPACE}', '/workspace/helm-salus-${_SALUS_APP}']
    env:
    - 'CLOUDSDK_COMPUTE_ZONE=${_CLOUDSDK_COMPUTE_ZONE}'
    - 'CLOUDSDK_COMPUTE_REGION=${_CLOUDSDK_COMPUTE_REGION}'
    - 'CLOUDSDK_CONTAINER_CLUSTER=${_CLOUDSDK_CONTAINER_CLUSTER}'
    - 'TILLERLESS=true'

  - name: gcr.io/cloud-builders/git
    id: E2E_SCRIPT_CLONE
    waitFor:
    - DEPLOY_APPLICATION
    args: ['clone', 'https://source.developers.google.com/p/$PROJECT_ID/r/github_rackspace-segment-support_monplat-k8s-env', '/workspace/monplat-k8s-env/']

  - name: gcr.io/cloud-builders/git
    id: HELM_E2E_CLONE
    waitFor:
    - DEPLOY_APPLICATION
    args: ['clone', 'https://source.developers.google.com/p/$PROJECT_ID/r/github_rackspace-segment-support_helm-salus-e2e', '/workspace/helm-salus-e2e/']

  - name: 'gcr.io/$PROJECT_ID/helm'
    id: RUN_E2E_TESTS
    entrypoint: bash
    args:
    - -c
    - |
      gcloud container clusters get-credentials ${_CLOUDSDK_CONTAINER_CLUSTER}
      export E2E_DEPLOYMENT="e2e-ci-$(head /dev/urandom | tr -dc a-z0-9 | head -c 13 ; echo '')"
      helm upgrade --install $${E2E_DEPLOYMENT} --set service.type='LoadBalancer' --wait /workspace/helm-salus-e2e
      /usr/bin/python3 /workspace/monplat-k8s-env/scripts/e2e-deploy.py ${_SALUS_APP} \
          --namespace ${_APP_NAMESPACE} \
          --endpoint "http://$(kubectl get svc $${E2E_DEPLOYMENT} -o jsonpath='{.status.loadBalancer.ingress[0].ip}')"
      helm del $${E2E_DEPLOYMENT}
    env:
    - 'CLOUDSDK_COMPUTE_ZONE=${_CLOUDSDK_COMPUTE_ZONE}'
    - 'CLOUDSDK_COMPUTE_REGION=${_CLOUDSDK_COMPUTE_REGION}'
    - 'CLOUDSDK_CONTAINER_CLUSTER=${_CLOUDSDK_CONTAINER_CLUSTER}'
    - 'TILLERLESS=true'

timeout: 1800s

options:
    substitution_option: 'ALLOW_LOOSE'
